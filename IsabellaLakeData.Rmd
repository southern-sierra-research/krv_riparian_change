---
title: "IsabellaLakeData"
author: "Patrick D. lorch"
date: "2025-04-09"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Lake Isabella data

Here is a link the the Army Corp website with hourly (H) and Daily (D) data going back to 1995:
https://www.spk-wc.usace.army.mil/plots/california.html

I imagine this data will be useful for multiple projects, but it makes sense to have it in krv_riparian_change, maintain it here, update it here, and grab it from here.

ToDo:

1. Set it up to import and combine years as needed.
2. Set it up to allow easy yearly updates
  a. Need to use readr to import with formatting or fix formatting where numbers have been imported as characters
2. Get it into a postgres database

## Get data from CSV files

Get a list of files downloaded and 

```{r lakeisabella}
library(dplyr)
library(tidyverse)

yearly_file_list = 
  list.files(file.path("C:",
                       "Users",
                       "PatrickLorch",
                       "SSRS",
                       "Southern Sierra Research Station - Documents",
                       "Projects",
                       "krv_riparian_change",
                       "Lake_Isabella_pool_ACOE_data1995to2025partial"),
             pattern = '\\.csv', full.names = TRUE)

# Not sure if it is worth finding ones that are partial and eliminating from list
basename(yearly_file_list[31])

# Read them into a tibble
lkisb = readr::read_csv(yearly_file_list, id = "file_name")

# Get a workable datetime
lkisb$DateTime = as.POSIXct(lkisb$`ISO 8601 Date Time`,
                            format = "%Y-%m-%dT%H:%M:%S")
lkisb$Year = year(lkisb$DateTime)
# Change to numeric
#  This will need to change if new imports change columns
tonumeric = names(lkisb)[c(3, 5, 7, 9, 11, 13, 15, 17, 19, 21,
                           23:28)]
lkisb = lkisb %>% mutate_at(tonumeric, as.numeric)

```

## Lake elevation by year

This method removes any lines that are blank for elevation before calculations.

```{r elev}

yearly_elevs = lkisb %>%
  group_by(Year) %>%
  filter(!is.na(`Elevation (ft-IPD)`)) %>%
  summarize(MaxElevation = max(`Elevation (ft-IPD)`),
         MinElevation = min(`Elevation (ft-IPD)`))
write.csv(yearly_elevs, "yearly_elevs.csv", row.names = F)

  

```


## Snow levels upstream of Lake Isabella

Snow levels are reported as Snow Water Equivalent (SWE) in inches.

Snow station data is from https://cdec.water.ca.gov/dynamicapp/staSearch

cdec_query from package cder and CDECquery from sharpshootR does not work. Returns 0 records.

CDECRetrieve needs to update something like20 packages, most of which are loaded.

ggdensity and ggridges did not seem to work.

ToDo:

* Map of where snow monitoring stations are

* stacked plot with multiple years and Water Year (WY) (Oct. 1 WY - 1) to Sept. 30 WY for arbitrary years
    * https://stackoverflow.com/questions/48123049/create-day-index-based-on-water-year

3. Area Under Curve estimates for each of these plots

```{r snow}
library(tidyverse)
library(readr)
library(sf)
library(leaflet)
library(lubridate)
library(ggplot2)
# install.packages("ggdensity")
# library(ggdensity)
# install.packages("ggridges")
# library(ggridges)
# installeaflet# install.packages("cder")
# library(cder)
# install.packages("sharpshootR")
# library(sharpshootR)
# library(devtools)
# install_git("https://github.com/FlowWest/CDECRetrieve.git")
# library(CDECRetrieve)

tn = names(lkisb)
snowsites = unique(substr(tn[grepl("SWE", tn)], 1, 3))
snowsites_files = list.files("SnowStations/", full.names = T)

snowsites.df =  readr::read_csv(snowsites_files, id = "file_name")

snowsites.sf = st_as_sf(snowsites.df,
                        coords = c("Longitude",
                                   "Latitude"),
                        crs = "4236")
leaflet() %>%
  # add different provider tiles
  addProviderTiles(
    "Esri.WorldImagery",
    group = "Esri.WorldImagery"
  ) %>%
  addProviderTiles(
    "OpenStreetMap",
    # give the layer a name
    group = "OpenStreetMap"
  ) %>%
# add a layers control
  addLayersControl(
    baseGroups = c(
      "Esri.WorldImagery", "OpenStreetMap"
    ),
    # position it on the topleft
    position = "topleft"
  ) %>%
  addMarkers(data = snowsites.df, 
             lng = ~Longitude,
             lat = ~Latitude,
             label = ~snowsites.df$"Station Name")

wy_start_md = "10-01"
wy_end_md = "09-30"

years_data = 
  sort(unique(lkisb$Year))
data.frame(start =
             as.POSIXct(paste(years_data - 1, wy_start_md, sep = "-")),
           end = as.POSIXct(paste(years_data , wy_end_md, sep = "-")))

wtr_yr <- function(dates, start_month=10) {
  # Convert dates into POSIXlt
  dates.posix = as.POSIXlt(dates)
  # Year offset
  offset = ifelse(dates.posix$mon >= start_month - 1, 1, 0)
  # Water year
  adj.year = dates.posix$year + 1900 + offset
  # Return the water year
  adj.year
}

lkisb$wtr_yr <-wtr_yr(lkisb$DateTime)

lkisb = lkisb %>%
  arrange(DateTime)

# ggplot
snow.cols = c("PSC SWE (in; elev 9,120 ft)",
                  "UTY SWE (in; elev 11,500 ft)",
                  "WTM SWE (in; elev 9,039 ft)")
lkisb.snow = lkisb %>%
  filter(DateTime < "2025-04-09") %>%
  select(DateTime, wtr_yr, snow.cols) %>%
  pivot_longer(cols = !c(DateTime, wtr_yr), 
               names_to = "Site", 
               values_to = "Snow Depth (in)") %>%
  mutate(Site.1st3 = substr(Site, 1, 3))

# Smaller data set for testing
lkisb.snow.wy11_12 = lkisb.snow %>%
  filter(wtr_yr %in% 2011:2012)

lkisb.snow %>%
  # filter(wtr_yr %in% 1994:1999) %>%
  # filter(wtr_yr %in% 2000:2009) %>%
  # filter(wtr_yr %in% 2010:2019) %>%
  filter(wtr_yr %in% 2020:2024) %>%
# lkisb.snow.wy11_12 %>%
  ggplot(aes(x = DateTime, 
           y = `Snow Depth (in)`, 
           fill = Site.1st3)) +
  geom_area() +
  labs(x = "Date", fill = "Site") +
  # scale_x_date(date_labels = "%b %d") +
  facet_wrap(~wtr_yr,  ncol=2, scales = "free_x") 

ggsave("LkIsabellaSnowDepth20_24.jpg", 
       height = 7, width = 9, units = "in")
ggsave("LkIsabellaSnowDepth20_24.pdf", 
       height = 7, width = 9, units = "in")

```

